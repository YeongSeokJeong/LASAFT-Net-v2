@inproceedings{xumx,
  title={All for One and One for All: Improving Music Separation by Bridging Networks},
  author={Sawata, Ryosuke and Uhlich, Stefan and Takahashi, Shusuke and Mitsufuji, Yuki},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={51--55},
  year={2021},
  organization={IEEE}
}

@article{kong,
  title={A Unified Model for Zero-shot Music Source Separation, Transcription and Synthesis},
  author={Lin, Liwei and Kong, Qiuqiang and Jiang, Junyan and Xia, Gus},
  journal={arXiv preprint arXiv:2108.03456},
  year={2021}
}

@article{demucs,
  title={Music Source Separation in the Waveform Domain},
  author={D{\'e}fossez, Alexandre and Usunier, Nicolas and Bottou, L{\'e}on and Bach, Francis},
  journal={arXiv preprint arXiv:1911.13254},
  year={2019}
}

@inproceedings{wisdom,
title	= {Unsupervised Sound Separation Using Mixture Invariant Training},
author	= {Scott Wisdom and Efthymios Tzinis and Hakan Erdogan and Ron J. Weiss and Kevin Wilson and John R. Hershey},
year	= {2020},
URL	= {https://arxiv.org/pdf/2006.12701.pdf},
booktitle	= {NeurIPS}
}

@inproceedings{attention,
  author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1409.0473},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{marg, Author = {Lee, Jie Hwan and Choi, Hyeong-Seok and Lee, Kyogu}, 
Booktitle = {20th International Society for Music Information Retrieval Conference}, Editor = {ISMIR}, Month = {November}, Title = {AUDIO QUERY-BASED MUSIC SOURCE SEPARATION.}, Year = {2019}}

@inproceedings{lasaft,
  title={LaSAFT: Latent Source Attentive Frequency Transformation for Conditioned Source Separation},
  author={Choi, Woosung and Kim, Minseok and Chung, Jaehwa and Jung, Soonyoung},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={171--175},
  year={2021},
  organization={IEEE}
}

@article{amssnet,
  title={AMSS-Net: Audio Manipulation on User-Specified Sources with Textual Queries},
  author={Choi, Woosung and Kim, Minseok and Ram{\'\i}rez, Marco A Mart{\'\i}nez and Chung, Jaehwa and Jung, Soonyoung},
  journal={arXiv preprint arXiv:2104.13553},
  year={2021}
}

@inproceedings{cunet, Author = {Meseguer-Brocal, Gabriel and Peeters, Geoffroy}, Booktitle = {20th International Society for Music Information Retrieval Conference}, Editor = {ISMIR}, Month = {November}, Title = {CONDITIONED-U-NET: Introducing a Control Mechanism in the U-net For Multiple Source Separations.}, Year = {2019}}

@inproceedings{meta,
  title={Meta-learning Extractors for Music Source Separation},
  author={Samuel, David and Ganeshan, Aditya and Naradowsky, Jason},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={816--820},
  year={2020},
  organization={IEEE}
}

@inproceedings{medical_unet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@inproceedings{svs_unet,
  title={Singing voice separation with deep u-net convolutional
networks},
  author={Jansson, Andreas and Humphrey, Eric and Montecchio, Nicola and Bittner, Rachel and Kumar, Aparna and Weyde, Tillman},
  booktitle={18th International Society for Music Information Retrieval
Conference},
  pages={745--751},
  year={2017},
}

@inproceedings{tfctdf, Author = {Choi, Woosung and Kim, Minseok and Chung, Jaehwa and Lee, Daewon and Jung, Soonyoung}, Booktitle = {21th International Society for Music Information Retrieval Conference}, Editor = {ISMIR}, Month = {OCTOBER}, Title = {Investigating U-Nets with various intermediate blocks for spectrogram-based singing voice separation.}, Year = {2020}}

@inproceedings{phasen,
  title={PHASEN: A Phase-and-Harmonics-Aware Speech Enhancement Network},
  author={Yin, Dacheng and Luo, Chong and Xiong, Zhiwei and Zeng, Wenjun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={9458--9465},
  year={2020}
}

@inproceedings{densenet,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{mmdenselstm,
  title={MMDenseLSTM: An efficient combination of convolutional and recurrent neural networks for audio source separation},
  author={Takahashi, Naoya and Goswami, Nabarun and Mitsufuji, Yuki},
  booktitle={2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC)},
  pages={106--110},
  year={2018},
  organization={IEEE}
}

@article{bss,
  title={Performance measurement in blind audio source separation},
  author={Vincent, Emmanuel and Gribonval, R{\'e}mi and F{\'e}votte, C{\'e}dric},
  journal={IEEE transactions on audio, speech, and language processing},
  volume={14},
  number={4},
  pages={1462--1469},
  year={2006},
  publisher={IEEE}
}

@misc{musdb18,
  TITLE = {{MUSDB18 - a corpus for music separation}},
  AUTHOR = {Rafii, Zafar and Liutkus, Antoine and St{\"o}ter, Fabian-Robert and Mimilakis, Stylianos Ioannis and Bittner, Rachel},
  URL = {https://hal.inria.fr/hal-02190845},
  NOTE = {MUSDB18: a corpus for music source separation},
  YEAR = {2017},
  MONTH = Dec,
  DOI = {10.5281/zenodo.1117371},
  KEYWORDS = {music separation ; dataset},
  PDF = {https://hal.inria.fr/hal-02190845/file/musdb.pdf},
  HAL_ID = {hal-02190845},
  HAL_VERSION = {v1},
}

@inproceedings{relu,
  title={Deep sparse rectifier neural networks},
  author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={315--323},
  year={2011}
}

@inproceedings{bn,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International Conference on Machine Learning},
  pages={448--456},
  year={2015}
}


@inproceedings{sisec,
  title={The 2018 signal separation evaluation campaign},
  author={St{\"o}ter, Fabian-Robert and Liutkus, Antoine and Ito, Nobutaka},
  booktitle={International Conference on Latent Variable Analysis and Signal Separation},
  pages={293--305},
  year={2018},
  organization={Springer}
}


@article{rmsprop,
  title={Neural networks for machine learning lecture 6a overview of mini-batch gradient descent},
  author={Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin},
  journal={Cited on},
  volume={14},
  pages={8},
  year={2012}
}

@inproceedings{blend,
  title={Improving music source separation based on deep neural networks through data augmentation and network blending},
  author={Uhlich, Stefan and Porcu, Marcello and Giron, Franck and Enenkl, Michael and Kemp, Thomas and Takahashi, Naoya and Mitsufuji, Yuki},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={261--265},
  year={2017},
  organization={IEEE}
}

@inproceedings{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dilatedlstm,
  title     = {Dilated Convolution with Dilated GRU for Music Source Separation},
  author    = {Liu, Jen-Yu and Yang, Yi-Hsuan},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {4718--4724},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcai.2019/655},
  url       = {https://doi.org/10.24963/ijcai.2019/655},
}

@inproceedings{d3net,
    author    = {Takahashi, Naoya and Mitsufuji, Yuki},
    title     = {Densely Connected Multi-Dilated Convolutional Networks for Dense Prediction Tasks},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {993-1002}
}

@inproceedings{film,
  title={FiLM: Visual Reasoning with a General Conditioning Layer},
  author={Perez, Ethan and Strub, Florian and de Vries, Harm and Dumoulin, Vincent and Courville, Aaron C},
  booktitle={AAAI},
  year={2018}
}

@article{nachmani,
  title={Voice Separation with an Unknown Number of Multiple Speakers},
  author={Nachmani, Eliya and Adi, Yossi and Wolf, Lior},
  journal={arXiv preprint arXiv:2003.01531},
  year={2020}
}
